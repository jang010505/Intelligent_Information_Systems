{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b53cfe",
   "metadata": {},
   "source": [
    "# 202001549 장희권"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd0807db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from konlpy.tag import Okt\n",
    "from PIL import Image\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed0173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"../../chromedriver.exe\")\n",
    "main_url = \"https://movie.daum.net/main\"\n",
    "driver.get(main_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc5c5d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name = '완벽한 타인'\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "search_path = '//*[@id=\"mainContent\"]/div/div[1]/form/fieldset/div/input'\n",
    "driver.find_element(\"xpath\", search_path).send_keys(movie_name)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "click_path = '//*[@id=\"mainContent\"]/div/div[1]/div/div/div/ul/li[1]/a'\n",
    "driver.find_element(\"xpath\", click_path).click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "gradeButton_path = '//*[@id=\"mainContent\"]/div/div[2]/div[1]/ul/li[4]/a'\n",
    "driver.find_element(\"xpath\", gradeButton_path).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "123e54f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewMore_path = '//*[@id=\"alex-area\"]/div/div/div/div[3]/div[1]/button'\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        driver.find_element(\"xpath\", viewMore_path).click()\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7d9f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = driver.page_source\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "grade_list = []\n",
    "\n",
    "cmt_lst = soup.find('ul', {\"class\":\"list_comment\"}).find_all('li')\n",
    "\n",
    "sentence_class_name = \"desc_txt\"\n",
    "ratings_class_name = \"ratings\"\n",
    "\n",
    "avg_grade = float(soup.find('em', {'class':'num_rating'}).text[:-1])\n",
    "\n",
    "for cmt in cmt_lst:\n",
    "    try:\n",
    "        rating = cmt.find('div', {'class':ratings_class_name}).text\n",
    "        sentence = cmt.find('p', {'class':sentence_class_name}).text\n",
    "        grade_list.append((int(rating), sentence))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "447dd097",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_grade_list = [(rating, sentence) for rating, sentence in grade_list if rating < avg_grade]\n",
    "good_grade_list = [(rating, sentence) for rating, sentence in grade_list if rating >= avg_grade]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaacaec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12bba5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('영화', 823),\n",
       " ('생각', 235),\n",
       " ('연기', 216),\n",
       " ('배우', 164),\n",
       " ('사람', 135),\n",
       " ('것', 114),\n",
       " ('이서진', 112),\n",
       " ('비밀', 111),\n",
       " ('유해진', 109),\n",
       " ('이', 78),\n",
       " ('공감', 77),\n",
       " ('보고', 77),\n",
       " ('나', 75),\n",
       " ('재미', 75),\n",
       " ('더', 75),\n",
       " ('점', 73),\n",
       " ('수', 69),\n",
       " ('정말', 67),\n",
       " ('시간', 67),\n",
       " ('그냥', 65)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_doc = '\\n'.join(list(zip(*grade_list))[1])\n",
    "grade_doc_noun = okt.nouns(grade_doc)\n",
    "\n",
    "grade_count_noun = Counter(grade_doc_noun)\n",
    "grade_count_noun.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ecef59d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'정말'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ff56854a12ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mstopword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopword_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mgrade_count_noun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mwc_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"white\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'C:\\Users\\user\\AppData\\Local\\Microsoft\\Windows\\Fonts\\NanumSquare.ttf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '정말'"
     ]
    }
   ],
   "source": [
    "stopword_list = {'보고', '정말', '그냥'}\n",
    "\n",
    "for text in grade_count_noun.copy():\n",
    "    if len(text) == 1:\n",
    "        stopword_list.add(text)\n",
    "\n",
    "for stopword in stopword_list:\n",
    "    grade_count_noun.pop(stopword)\n",
    "    \n",
    "wc_img = WordCloud(background_color=\"white\", max_words=2000, font_path=r'C:\\Users\\user\\AppData\\Local\\Microsoft\\Windows\\Fonts\\NanumSquare.ttf')\n",
    "wc_img = wc_img.generate_from_frequencies(grade_count_noun)\n",
    "\n",
    "plt.imshow(wc_img, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8154aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_grade_doc = '\\n'.join(list(zip(*bad_grade_list))[1])\n",
    "bad_grade_doc_noun = okt.nouns(bad_grade_doc)\n",
    "\n",
    "bad_grade_count_noun = Counter(bad_grade_doc_noun)\n",
    "bad_grade_count_noun.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63b9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = {'보고', '그냥'}\n",
    "\n",
    "for text in bad_grade_count_noun.copy():\n",
    "    if len(text) == 1:\n",
    "        stopword_list.add(text)\n",
    "\n",
    "for stopword in stopword_list:\n",
    "    bad_grade_count_noun.pop(stopword)\n",
    "    \n",
    "wc_img = WordCloud(background_color=\"white\", max_words=2000, font_path=r'C:\\Users\\user\\AppData\\Local\\Microsoft\\Windows\\Fonts\\NanumSquareR.ttf')\n",
    "wc_img = wc_img.generate_from_frequencies(bad_grade_count_noun)\n",
    "\n",
    "plt.imshow(wc_img, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2235f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_grade_doc = '\\n'.join(list(zip(*good_grade_list))[1])\n",
    "good_grade_doc_noun = okt.nouns(good_grade_doc)\n",
    "\n",
    "good_grade_count_noun = Counter(good_grade_doc_noun)\n",
    "good_grade_count_noun.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8567b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = {'보고', '정말', '간만'}\n",
    "\n",
    "for text in good_grade_count_noun.copy():\n",
    "    if len(text) == 1:\n",
    "        stopword_list.add(text)\n",
    "\n",
    "for stopword in stopword_list:\n",
    "    good_grade_count_noun.pop(stopword)\n",
    "    \n",
    "wc_img = WordCloud(background_color=\"white\", max_words=2000, font_path=r'C:\\Users\\user\\AppData\\Local\\Microsoft\\Windows\\Fonts\\NanumSquareR.ttf')\n",
    "wc_img = wc_img.generate_from_frequencies(good_grade_count_noun)\n",
    "\n",
    "plt.imshow(wc_img, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "11ddfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNaiveBayesClassifier:\n",
    "    def __init__(self, k=0.5, use_morph=False):\n",
    "        self.k = k\n",
    "        self.word_prob_list = []\n",
    "        self.word_ratio_list = []\n",
    "        self.use_morph = use_morph\n",
    "        \n",
    "        if self.use_morph:\n",
    "            self.okt = Okt()\n",
    "            \n",
    "    def load_data(self, grade_list):\n",
    "        lst = [(text, 'pos') if grade >= avg_grade else (text, 'neg') for grade, text in grade_list]\n",
    "        return zip(*lst)\n",
    "\n",
    "    def tokenize(self, sentence):\n",
    "        if self.use_morph:\n",
    "            return [\"{0}/{1}\".format(word, tag) for word, tag in self.okt.pos(sentence, norm=True, stem=True)]\n",
    "        else:\n",
    "            return sentence.split()\n",
    "    \n",
    "    def count_words(self, docs, labels):\n",
    "        count_dict = defaultdict(lambda:{'pos': 0, 'neg':0})\n",
    "        for doc, label in zip(docs, labels):\n",
    "            for word in self.tokenize(doc):\n",
    "                count_dict[word][label] += 1\n",
    "        \n",
    "        print('num of words... {0}'.format(len(count_dict)))\n",
    "        return count_dict\n",
    "    \n",
    "    def word_prob(self, count_dict, pos_class_num, neg_class_num, k):\n",
    "        word_prob_list = []\n",
    "        \n",
    "        for word in count_dict.keys():\n",
    "            pos_word_num = count_dict[word]['pos']\n",
    "            neg_word_num = count_dict[word]['neg']\n",
    "            \n",
    "            pos_class_prob = (pos_word_num + k) / (pos_class_num + 2*k)\n",
    "            neg_class_prob = (neg_word_num + k) / (neg_class_num + 2*k)\n",
    "            \n",
    "            word_prob_list.append((word, pos_class_prob, neg_class_prob))\n",
    "        \n",
    "        return word_prob_list\n",
    "    \n",
    "    def class_prob(self, word_prob_list, test_sentence, use_unseen=False):\n",
    "        test_words = self.tokenize(test_sentence)\n",
    "        \n",
    "        sent_log_pos_class_prob, sent_log_neg_class_prob = 0.0, 0.0\n",
    "        \n",
    "        for word, word_pos_class_prob, word_neg_class_prob in word_prob_list:\n",
    "            if word in test_words:\n",
    "                sent_log_pos_class_prob += math.log(word_pos_class_prob) \n",
    "                sent_log_neg_class_prob += math.log(word_neg_class_prob)\n",
    "            else:\n",
    "                if use_unseen:\n",
    "                    sent_log_pos_class_prob += math.log(1-word_pos_class_prob) \n",
    "                    sent_log_neg_class_prob += math.log(1-word_neg_class_prob)\n",
    "            \n",
    "        sent_pos_class_prob = math.exp(sent_log_pos_class_prob)\n",
    "        sent_neg_class_prob = math.exp(sent_log_neg_class_prob)\n",
    "        \n",
    "        pos_class_prob = sent_pos_class_prob/(sent_pos_class_prob+sent_neg_class_prob)\n",
    "        neg_class_prob = sent_neg_class_prob/(sent_pos_class_prob+sent_neg_class_prob)\n",
    "        \n",
    "        return pos_class_prob, neg_class_prob\n",
    "    \n",
    "    def word_ratio(self, word_prob_list):\n",
    "        word_ratio_list = [(text, pos/pos, neg/pos) if pos < neg else (text, pos/neg, neg/neg) for text, pos, neg in self.word_prob_list]\n",
    "        return list(sorted(word_ratio_list, key=lambda x: x[1]*x[2], reverse=True))\n",
    "    \n",
    "    def train(self, train_file_path):\n",
    "        train_docs, train_labels = self.load_data(train_file_path)\n",
    "        \n",
    "        word_count_dict = self.count_words(train_docs, train_labels)\n",
    "        \n",
    "        pos_class_num = len([label for label in train_labels if label == 'pos'])\n",
    "        neg_class_num = len([label for label in train_labels if label == 'neg'])\n",
    "        \n",
    "        self.word_prob_list = self.word_prob(word_count_dict, pos_class_num, neg_class_num, self.k)\n",
    "        self.word_ratio_list = self.word_ratio(self.word_prob_list)\n",
    "        \n",
    "    def classify(self, test_sentence, use_unseen=False):\n",
    "        pos_class_prob, neg_class_prob = self.class_prob(self.word_prob_list, test_sentence, use_unseen)\n",
    "        \n",
    "        if pos_class_prob > neg_class_prob:\n",
    "            print('pos', pos_class_prob)\n",
    "        else:\n",
    "            print('neg', neg_class_prob)\n",
    "    \n",
    "    def show_most_informative_features(self, show_count=10, type=\"all\"):\n",
    "        count = 0\n",
    "        for text, pos, neg in self.word_ratio_list:\n",
    "            if count < show_count:\n",
    "                if (type == \"all\") or  (type == \"pos\" and pos >= neg) or (type == 'neg' and neg > pos):\n",
    "                    count += 1\n",
    "                    print(\"{0} -> pos : neg = {1:.1f} : {2:.1f}\".format(text, pos, neg))\n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "958931e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MyNaiveBayesClassifier(use_morph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "22f57dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of words... 4161\n"
     ]
    }
   ],
   "source": [
    "classifier.train(grade_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "078299f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어색/Noun -> pos : neg = 1.0 : 35.0\n",
      "의도/Noun -> pos : neg = 1.0 : 30.9\n",
      "냐/Josa -> pos : neg = 1.0 : 30.9\n",
      "수준/Noun -> pos : neg = 1.0 : 29.5\n",
      "노잼/Noun -> pos : neg = 1.0 : 26.7\n",
      "보헤미안/Noun -> pos : neg = 1.0 : 26.7\n",
      "안좋다/Adjective -> pos : neg = 1.0 : 26.7\n",
      "더럽다/Adjective -> pos : neg = 1.0 : 22.6\n",
      "속이다/Verb -> pos : neg = 1.0 : 22.6\n",
      "부인/Noun -> pos : neg = 1.0 : 22.6\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(type=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1adf0848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos 0.826862712175726\n"
     ]
    }
   ],
   "source": [
    "classifier.classify('영화 재미있다', use_unseen=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c84729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
